AI101 REFLECTION 


The AI100 report captures a lot of interesting points on benefits, dangers, and regulations around AI. It doesn’t capture in depth how AI-backed algorithms used in social media platforms like Twitter and Facebook have been weaponized to meddle in elections. One of the big criticism of AI in recent times has been from the Cambridge Analytica and Facebook scandal (1), where with the help of the data available via the Facebook platform an algorithm was used for psychological targeting of the masses to influence elections in the United States and Brexit campaign in the UK (1,2,3). Nowadays it is not uncommon to see Machine learning algorithms used to generate analytics to supplement political campaigns. Using such tools it is easy to grasp the trends, regional needs of the people, and common demographic and cater the campaigns granularly to secure victory and connect with people. But it doesn’t stop there, using the same understanding one can use these algorithms to create deep engagement to portray misinformation that would benefit oneself. Information on wrong election timings, or dispersing improper agendas of competitors to turn people was one of the many techniques used in the 2016 US elections. Utilizing automated bot accounts to portray engagement and spam the threads with disinformation to influence the users is common in recent times (4). This often leads to biased outcomes and perpetuates existing societal inequalities, as AI algorithms are only as unbiased as the data or the use case they are trained for. This can result in discriminatory practices, such as targeted advertising based on gender, race, or political affiliation, and the spread of fake news. Since this discovery, there has been pressure from the government, regulatory, and ethics community to ensure that social media and internet companies be transparent in the data being collected and its usage without the knowledge of the user. For example, Facebook collected vast amounts of personal information from its users, including their demographics, interests, preferences, location data, sms, and many more. Most users are unaware of the scale collection and the use of such data (5). This transparency still hasn’t reached the basic user which covers the majority of the internet. The terms and conditions on websites are still portrayed as a barrier to entry into the website and the language in those conditions is convoluted leading to most users just clicking through them not knowing what they are consenting to. This is particularly severe in countries that are still in their infancy of data laws (for ex: India) and the issues before the scandals are still prevalent today. Basic data privacy laws shouldn’t be state or country law, but rather universally adhered law. 
Stringency needs to be done to educate the user on the data collection and clarity must be provided on the use of the data. As the current and upcoming generations become more tech-savvy, the majority of politics would be played on the AI-enabled social media platform and strict laws and adherence is the need of the hour (6).